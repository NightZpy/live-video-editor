# ConfiguraciÃ³n de Variables de Entorno

Este proyecto utiliza variables de entorno para una configuraciÃ³n segura y flexible. AquÃ­ te explicamos cÃ³mo configurarlas.

## ðŸ”§ ConfiguraciÃ³n RÃ¡pida

### 1. Crear archivo .env

Copia el archivo de ejemplo y renÃ³mbralo:
```bash
cp .env.example .env
```

### 2. Editar el archivo .env

Abre `.env` en tu editor y completa los valores:

```env
# OpenAI API Key - OBLIGATORIO
OPENAI_API_KEY=sk-tu-api-key-real-aqui

# ConfiguraciÃ³n opcional del modelo por defecto
DEFAULT_MODEL=gpt-4o-mini

# ConfiguraciÃ³n de tokens mÃ¡ximos
MAX_COMPLETION_TOKENS=8192
```

### 3. Obtener tu API Key de OpenAI

1. Ve a [OpenAI Platform](https://platform.openai.com/api-keys)
2. Inicia sesiÃ³n en tu cuenta
3. Haz clic en "Create new secret key"
4. Copia la clave y pÃ©gala en tu archivo `.env`

## ðŸ›¡ï¸ Seguridad

- **NUNCA** subas el archivo `.env` a Git (ya estÃ¡ en `.gitignore`)
- **NUNCA** compartas tu API key pÃºblicamente
- **NUNCA** hardcodees la API key en el cÃ³digo

## ðŸ“‹ Variables Disponibles

| Variable | DescripciÃ³n | Valor por defecto | Requerida |
|----------|-------------|-------------------|-----------|
| `OPENAI_API_KEY` | Tu clave de API de OpenAI | - | âœ… SÃ­ |
| `DEFAULT_MODEL` | Modelo principal a usar | `gpt-4o-mini` | âŒ No |
| `MAX_COMPLETION_TOKENS` | LÃ­mite de tokens por respuesta | `8192` | âŒ No |

## ðŸ’» Uso en el CÃ³digo

### OpciÃ³n 1: Solo con variables de entorno
```python
from src.core.llm_cuts_processor import LLMCutsProcessor

# Usa automÃ¡ticamente OPENAI_API_KEY del .env
processor = LLMCutsProcessor()
```

### OpciÃ³n 2: API key manual (sobrescribe .env)
```python
# Sobrescribe la variable de entorno
processor = LLMCutsProcessor(api_key="sk-tu-api-key-manual")
```

### OpciÃ³n 3: ConfiguraciÃ³n personalizada
```python
import os

# Cambiar configuraciÃ³n temporalmente
os.environ['DEFAULT_MODEL'] = 'gpt-4.1'
os.environ['MAX_COMPLETION_TOKENS'] = '12000'

processor = LLMCutsProcessor()
```

## ðŸ”§ Modelos Soportados

El sistema usa una estrategia de fallback automÃ¡tica con estos modelos:

1. **Modelo principal** (configurado en `DEFAULT_MODEL`)
2. **gpt-4o-mini** (fallback rÃ¡pido y econÃ³mico)
3. **gpt-4.1-mini** (fallback balanceado)
4. **gpt-4.1** (fallback mÃ¡s capaz)

Si el primer modelo falla, automÃ¡ticamente prueba con el siguiente.

## ðŸš¨ SoluciÃ³n de Problemas

### Error: "No OpenAI API key provided"
- âœ… Verifica que el archivo `.env` existe
- âœ… Verifica que `OPENAI_API_KEY` estÃ¡ definida en `.env`
- âœ… Verifica que no hay espacios extras en el valor

### Error: "Invalid API key"
- âœ… Verifica que la API key es correcta
- âœ… Verifica que tienes crÃ©ditos en tu cuenta de OpenAI
- âœ… Verifica que la clave no ha expirado

### Error: "Model not found"
- âœ… Verifica que el modelo estÃ¡ disponible en tu cuenta
- âœ… Usa un modelo estÃ¡ndar como `gpt-4o-mini`

## ðŸ“ Ejemplo Completo

```bash
# 1. Crear .env
cp .env.example .env

# 2. Editar .env con tu API key
echo "OPENAI_API_KEY=sk-tu-api-key-aqui" > .env

# 3. Probar configuraciÃ³n
python ejemplo_env_usage.py
```

## ðŸ”„ MigraciÃ³n desde Versiones Anteriores

Si estabas pasando la API key manualmente, ahora puedes:

**Antes:**
```python
processor = LLMCutsProcessor(api_key="sk-hardcoded-key")
```

**Ahora (recomendado):**
```python
# Configurar en .env: OPENAI_API_KEY=sk-tu-key
processor = LLMCutsProcessor()
```

**Compatibilidad:**
```python
# Sigue funcionando, pero no es recomendado
processor = LLMCutsProcessor(api_key="sk-manual-key")
```
